[CRAB]

jobtype = cmssw
scheduler = glite
### NOTE: just setting the name of the server (pi, lnl etc etc )
###       crab will submit the jobs to the server...
#server_name = bari

[CMSSW]

### The data you want to access (to be found on DBS)
# these are AODs
# datasetpath=/ttbar_inclusive_xTopRex/CMSSW_1_3_1-Spring07-1122/GEN-SIM-DIGI-RECO
# datasetpath=/Zmumu/Summer08_IDEAL_V9_v1/GEN-SIM-RECO
# datasetpath=/ZJets-madgraph/Summer08_IDEAL_V9_v1/GEN-SIM-RECO
# datasetpath=/WJets-madgraph/Summer08_IDEAL_V9_v1/GEN-SIM-RECO
# datasetpath=/TTJets-madgraph/Summer08_IDEAL_V9_v2/GEN-SIM-RECO
# datasetpath=/InclusiveMuPt15/Summer08_IDEAL_V9_v1/GEN-SIM-RECO
# datasetpath=/ZJets-madgraph/Fall08_IDEAL_V9_v1/GEN-SIM-RECO
# here below are PATtuples
# datasetpath=/WJets-madgraph/Summer08_IDEAL_V9_PAT_v4/USER
datasetpath=/ZJets-madgraph/Summer08_IDEAL_V9_PAT_v3/USER

### The ParameterSet you want to use
# these are for the AODs 2_1_9
#pset=patLayer1_fromAOD_full.cfg.py
#pset=patLayer1_fromAOD_jetSuite_full.cfg.py
#pset=patLayer1_fromAOD_sisConegen_full.cfg.py
# these are for the PAttuples 2_2_4
pset=MADGRAPH_PAT2_cfg.py

### Splitting parameters
total_number_of_events=1000000
# full sample
# total_number_of_events=1000000
# events_per_job = 10000
# test with 50K
# total_number_of_events=50000
# events_per_job = 5000
## total_number_of_events=100
## events_per_job = 100
# below is for PAT ntuples
number_of_jobs = 10

### The output files (comma separated list)
# here below are for AODS to PAT
# output_file = PATLayer1_Output.fromAOD_full.root
# sisCone standard 
# output_file=PATLayer1_Output.fromAOD_sisCone_full.root
# different jet finders
# output_file=PATLayer1_Output.fromAOD_sisConegen_full.root
# output_file=PATLayer1_Output.fromAOD_sisConegenPythia_full.root
# output_file=PATLayer1_Output.fromAOD_sisConegenMadgraphBS_full.root
# these are for PAT to ZJetsFirenze format
# output_file=WJetsMadGraphSummer08.root
output_file=ZJetsMadGraphSummer08.root

[USER]

### OUTPUT files Management
##  output back into UI
return_data = 0

### OUTPUT files INTO A SE
copy_data = 1
storage_element = srm-cms.cern.ch
## old way storage_path = /srm/managerv2?SFN=/castor/cern.ch/user/e/egallo/ZmumuV9
storage_path=/srm/managerv2?SFN=/castor/cern.ch
user_remote_dir=/user/e/egallo/Zmumu/
# old way before crab_2_4 lfn=/user/e/egallo/Zmumu/SisCone100

### if you are using CAF scheduler, you can specify the pool
### where to write your output. The default is cmscafuser 
#storage_pool = cmscafuser 

#if server
#thresholdLevel = 100
#eMail = your@Email.address

[EDG]

## RB/WMS management:
rb = CERN

##  Black and White Lists management:
## By Storage
se_black_list = T0,T1
#se_white_list =

## By ComputingElement
#ce_black_list =
#ce_white_list =

[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))

